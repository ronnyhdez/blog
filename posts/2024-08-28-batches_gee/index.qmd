---
title: "A Step-by-Step Guide to Exporting 'Large' Datasets to Google Earth Engine via Python"
description: "If you've encountered the dreaded `Request payload size exceeds the limit` error, you're not alone."
date: 2024-09-07
categories: [GEE, batch, API]
licence: "CC BY-NC"
image: alberta.png
jupyter: python3
editor_options: 
  chunk_output_type: console
bibliography: ref.bib
---

Have you ever found yourself pre-processing a local geodatabase, expecting to
use the cleaned version on Google Earth Engine (GEE), only to get stuck when
you try to export it as an asset? After a few seconds waiting for the task to
complete the get the message: `ee.ee_exception.EEException: Request payload size exceeds the limit: 10485760 bytes.`

You might consider exporting it as a `.shp` file and manually uploading it to 
GEE, but we both know thatâ€™s not an ideal, long-term solution. Our goal is to 
maintain streamlined, code-base approach for our project. 

So, how can we export our exceeding API rate limit data without doing any manual
export? The answer: divide and conquer!

In this tutorial, we'll work on a approach that allows us to:

 1. Divide our data into manageable chunks.
 2. Export these batches as assets to GEE programmatically.
 3. Consolidate the uploaded batches into a single asset within GEE.

## Setting Up the Environment

Before we dive into the main process, let's set up our environment and import 
the necessary libraries and initialize GEE:

```{python}
import geopandas as gpd
import os
import sys
import janitor
import ee
import json
import math

# Initialize Google Earth Engine
ee.Initialize()
```

# Read and pre-process the data

For this tutorial, we'll use a dataset of reservoirs polygons from the province
of Alberta, Canada. This dataset is provided by the Alberta Biodiversity 
Monitoring Institute (ABMI) [@abmi_hfi_2021].

```{python}
# Set the path to your geodatabase
path = str(os.getcwd()) + '/data_check/HFI2021.gdb'
print(f'Reading data from: {path}')

# Read the specific layer from the geodatabase
reservoirs = gpd.read_file(path, layer = 'o01_Reservoirs_HFI_2021')

# Clean column names and select necessary columns
reservoirs = reservoirs.clean_names()
reservoirs = reservoirs[['feature_ty', 'geometry']]

print(reservoirs.head())
print(f'Total number of reservoirs: {len(reservoirs)}')
print(f'CRS: {reservoirs.crs}')
```

In this step, we read a specific layer from our dataset, clean the column names,
and select only the necessary columns. While additional pre-processing steps can
be performed locally, in this case, we focus on selecting the specific data we 
need. Additionally, we print the number of observations included in the layer
and the CRS.

# The API Limit Challenge

If we try to export this entire dataset to GEE at once, we'll encounter an error
due to the API's payload size limit:

::: {.column-margin}
From this point forward, whenever you see 'projects/ee-ronnyale/assets/', be 
sure to replace it with your own GEE project path.
:::
```{python}
#| error: true

# This code will raise an error due to payload size
reservoirs_geojson = reservoirs.to_json()
reservoirs_fc = ee.FeatureCollection(json.loads(reservoirs_geojson))
exportTask = ee.batch.Export.table.toAsset(
    collection = reservoirs_fc,
    description = 'Cleaned Reservoirs Export',
    assetId = 'projects/ee-ronnyale/assets/reservoirs'
)
exportTask.start()
```

# Exporting Data in Batches

To overcome the API rate limit, we'll divide our data into manageable batches 
and upload them individually. This approach has a trade-off: it will create
multiple assets in GEE, which we'll need to merge later. Here's how we'll do it:

 1. Define a batch size
 2. Calculate the number of batches needed
 3. Loop through the data, creating and uploading each batch
 4. Assign a unique ID to each batch for easy identification

One crucial step: before uploading, we'll change the CRS to `epsg=4326`, which 
is used by GEE. This prevents distortion of the polygons when working in GEE.

```{python}
#| error: true
ee.Initialize()

# Define the batch size
batch_size = 500

# Calculate the number of batches needed
num_batches = math.ceil(len(reservoirs) / batch_size)

for i, batch in enumerate(reservoirs.groupby(reservoirs.index // batch_size)):
    # Reproject to WGS 84 (EPSG:4326)
    batch = batch[1].to_crs(epsg = 4326)

    # Convert to GeoJSON
    batch_geojson = batch.to_json()

    # Load GeoJSON as an Earth Engine FeatureCollection
    batch_fc = ee.FeatureCollection(json.loads(batch_geojson))

    # Define a unique asset ID for each batch
    batch_asset_id = f'projects/ee-ronnyale/assets/reservoirs_batch_{i+1}'

    # Export the batch to GEE
    print(f'Exporting the batch: {batch_asset_id}')
    exportTask = ee.batch.Export.table.toAsset(
        collection = batch_fc,
        description = f'Reservoirs Batch {i+1}',
        assetId = batch_asset_id
    )

    # Start the export task
    exportTask.start()
```

There we have. In total, there are 17 new assets in GEE. Now I need to merge 
all of them into one single asset.

On your GEE assets you should be able to see something like:

![Batches as assets in GEE](images/reservoirs_batches.png)

# Merge assets in one

I have to define in a list all the assets I want to merge. So, I will create a list taking advantage of the name pattern that the individual reservoirs assets have (just the final id batch number changes)

Then I will loop on each one and merge them. This will create an object that lives in GEE but it's not saved. That's why I will need to export it as the new merged asset

```{python}
#| error: true
batch_asset_ids = [f'projects/ee-ronnyale/assets/reservoirs_batch_{i+1}' for i in range(num_batches)]
reservoirs_fc = ee.FeatureCollection(batch_asset_ids[0])
for asset_id in batch_asset_ids[1:]:
    batch_fc = ee.FeatureCollection(asset_id)
    reservoirs_fc = reservoirs_fc.merge(batch_fc)

exportTask = ee.batch.Export.table.toAsset(
    collection=reservoirs_fc,
    description='Merged Reservoirs',
    assetId='projects/ee-ronnyale/assets/reservoirs_merged'
)
exportTask.start()
```

# Removing individual assets

Finally, we ended up with many reservoirs assets (one per each batch) and the merged reservoirs asset. I just need the final one, so I want to remove the rest. Instead of doing this manually click-ing each one in GEE, I'm can do it in a loop:

```{python}
#| error: true
for asset_id in batch_asset_ids:
    try:
        ee.data.deleteAsset(asset_id)
    except Exception as e:
```

# Steps summary

Here is the complete steps with some `prints()` that will inform the user what is happening when running the code:

```{python}
#| error: true
ee.Initialize()

# Define the batch size
batch_size = 500

# Calculate the number of batches needed
num_batches = math.ceil(len(reservoirs) / batch_size)
print(f'Total of batches to export: {num_batches}')

# for i, batch in enumerate(reservoirs.groupby(reservoirs.index // batch_size)):
#     # Reproject to WGS 84 (EPSG:4326)
#     batch = batch[1].to_crs(epsg=4326)

#     # Convert to GeoJSON
#     batch_geojson = batch.to_json()

#     # Load GeoJSON as an Earth Engine FeatureCollection
#     print(f'Transformin to json batch {i}')
#     batch_fc = ee.FeatureCollection(json.loads(batch_geojson))

#     # Define a unique asset ID for each batch
#     batch_asset_id = f'projects/ee-ronnyale/assets/reservoirs_batch_{i+1}'

#     # Export the batch to GEE
#     print(f'Exporting the batch: {batch_asset_id}')
#     exportTask = ee.batch.Export.table.toAsset(
#         collection=batch_fc,
#         description=f'Reservoirs Batch {i+1}',
#         assetId=batch_asset_id
#     )

#     # Start the export task
#     exportTask.start()


# Steps to join batches in 1 collection:
## I have the number of batches to create the list
## 

# batch_asset_ids = [f'projects/ee-ronnyale/assets/reservoirs_batch_{i+1}' for i in range(num_batches)]
# reservoirs_fc = ee.FeatureCollection(batch_asset_ids[0])
# for asset_id in batch_asset_ids[1:]:
#     batch_fc = ee.FeatureCollection(asset_id)
#     reservoirs_fc = reservoirs_fc.merge(batch_fc)

# print(f'Total number of features: {reservoirs_fc.size().getInfo()}')

# # Example: Export the merged collection to another asset (if needed)
# exportTask = ee.batch.Export.table.toAsset(
#     collection=reservoirs_fc,
#     description='Merged Reservoirs',
#     assetId='projects/ee-ronnyale/assets/reservoirs_merged'
# )
# exportTask.start()

# for asset_id in batch_asset_ids:
#     try:
#         ee.data.deleteAsset(asset_id)
#         print(f'Successfully deleted: {asset_id}')
#     except Exception as e:
#         print(f'Failed to delete {asset_id}: {e}')
```
